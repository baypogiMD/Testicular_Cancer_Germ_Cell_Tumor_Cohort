import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.metrics import (
    roc_auc_score, accuracy_score, precision_score,
    recall_score, f1_score, classification_report,
    confusion_matrix, RocCurveDisplay
)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

from catboost import CatBoostClassifier

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid", context="talk")
plt.rcParams["figure.figsize"] = (8, 6)

print("Modeling libraries loaded.")

DATA_PATH = "../data/processed/testicular_cancer_engineered.csv"

df = pd.read_csv(DATA_PATH)

df.head()

feature_cols = [
    "age_at_diagnosis",
    "high_t_stage",
    "node_positive",
    "metastatic",
    "marker_elevated",
    "tmb_log"
]

X = df[feature_cols]
y = df["target"]

print("Class distribution:")
print(y.value_counts(normalize=True))

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.25,
    stratify=y,
    random_state=42
)

print("Train size:", X_train.shape)
print("Test size:", X_test.shape)

log_reg = LogisticRegression(
    class_weight="balanced",
    max_iter=1000,
    random_state=42
)

log_reg.fit(X_train, y_train)

y_pred_lr = log_reg.predict(X_test)
y_prob_lr = log_reg.predict_proba(X_test)[:, 1]

print("Logistic Regression Results")
print(classification_report(y_test, y_pred_lr))
print("ROC-AUC:", roc_auc_score(y_test, y_prob_lr))

rf = RandomForestClassifier(
    n_estimators=300,
    max_depth=5,
    class_weight="balanced",
    random_state=42
)

rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)
y_prob_rf = rf.predict_proba(X_test)[:, 1]

print("Random Forest Results")
print(classification_report(y_test, y_pred_rf))
print("ROC-AUC:", roc_auc_score(y_test, y_prob_rf))

cat_model = CatBoostClassifier(
    iterations=500,
    learning_rate=0.05,
    depth=4,
    loss_function="Logloss",
    eval_metric="AUC",
    verbose=False,
    random_state=42
)

cat_model.fit(X_train, y_train)

y_pred_cat = cat_model.predict(X_test)
y_prob_cat = cat_model.predict_proba(X_test)[:, 1]

print("CatBoost Results")
print(classification_report(y_test, y_pred_cat))
print("ROC-AUC:", roc_auc_score(y_test, y_prob_cat))

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

models = {
    "Logistic Regression": log_reg,
    "Random Forest": rf,
    "CatBoost": cat_model
}

cv_results = {}

for name, model in models.items():
    scores = cross_val_score(
        model, X, y,
        scoring="roc_auc",
        cv=cv
    )
    cv_results[name] = scores

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

models = {
    "Logistic Regression": log_reg,
    "Random Forest": rf,
    "CatBoost": cat_model
}

cv_results = {}

for name, model in models.items():
    scores = cross_val_score(
        model, X, y,
        scoring="roc_auc",
        cv=cv
    )
    cv_results[name] = scores

cv_df = pd.DataFrame({
    "model": cv_results.keys(),
    "mean_auc": [scores.mean() for scores in cv_results.values()],
    "std_auc": [scores.std() for scores in cv_results.values()]
})

cv_df

plt.figure()

RocCurveDisplay.from_predictions(y_test, y_prob_lr, name="Logistic Regression")
RocCurveDisplay.from_predictions(y_test, y_prob_rf, name="Random Forest")
RocCurveDisplay.from_predictions(y_test, y_prob_cat, name="CatBoost")

plt.title("ROC Curve Comparison")
plt.show()

cm = confusion_matrix(y_test, y_pred_cat)

sns.heatmap(
    cm,
    annot=True,
    fmt="d",
    cmap="Blues",
    xticklabels=["Tumor Free", "With Tumor"],
    yticklabels=["Tumor Free", "With Tumor"]
)

plt.title("Confusion Matrix â€” CatBoost")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

performance_summary = pd.DataFrame({
    "Model": ["Logistic Regression", "Random Forest", "CatBoost"],
    "ROC-AUC": [
        roc_auc_score(y_test, y_prob_lr),
        roc_auc_score(y_test, y_prob_rf),
        roc_auc_score(y_test, y_prob_cat)
    ]
})

performance_summary

